---
title: 'Backpropagation for LIFs (WIP)'
excerpt: "We figure out how BPTT works for LIFs (WIP)"
date: 2025-11-22
permalink: /posts/2025/11/bptt/
tags:
  - JAX
  - SNN
  - Tutorial
  - bptt
---

<div class="notice--info" markdown="1">
**Note:** Parts of this tutorial are based on the wonderful [snnTorch tutorial by Eshraghian et al.](https://snntorch.readthedocs.io/en/latest/tutorials/tutorial_5.html){:target="_blank"} However, some parts were not entirely clear to me from their tutorial so I made my own. The notation is also mostly consistent with their [2023 paper](https://ieeexplore.ieee.org/abstract/document/10242251/){:target="_blank"}.
</div>

Backpropagation through time (BPTT) is probably the most popular way of training Spiking Neural Networks. Today we will walk through some of the mathematics of the method. By the end of this article, you will be able to calculate all gradients by hand on paper if you have to.

This post assumes familiarity with the [LIF neuron dynamics](/posts/2025/10/lif-theory/).

## The Setup
Let's assume we have a single leaky integrate-and-fire (LIF) neuron with a single incoming connection $$\textcolor{red}{W_{in}}$$ and there are no recurrent connections, as shown in [Figure 1](#fig:neuron_diagram).

<details style="background-color: #f9f9f9; border: 1px solid #ddd; border-radius: 4px; padding: 10px; margin: 15px 0;">
<summary style="cursor: pointer; font-weight: bold; color: #4a90e2;">Why use capital letters?</summary>
<p style="margin-top: 10px;">Despite the fact that it's a scalar we use a capital letter as though it were a matrix. That's because it works exactly the same either way, so it will be more consistent for later steps.</p>
</details>

<figure id="fig:neuron_diagram">
<div id="lif-neuron-diagram" data-label-input="X[t]" data-label-weight="Wᵢₙ" data-label-state="U[t]" data-label-output="S[t]" data-label-prev-state="U[t-1]" style="width: 100%; margin: 2em auto;"></div>
<figcaption><strong>Figure 1:</strong> Simple LIF neuron setup with input X[t], membrane potential U[t], input weight W<sub>in</sub>, decay α, and output spike S[t].</figcaption>
</figure>

<script src="{{ '/assets/js/lif-diagram.js' | relative_url }}"></script>

In this case we can describe the membrane potential $$\textcolor{ForestGreen}{U[t]}$$ as:

\begin{equation}
\textcolor{ForestGreen}{U[t]} = \textcolor{blue}{\alpha} \textcolor{ForestGreen}{U[t-1]} + \textcolor{red}{W_{in}} \textcolor{purple}{X[t]} - \textcolor{orange}{S[t-1]} \textcolor{brown}{\theta}
\label{eq:lif_full}
\end{equation}

where $$\textcolor{blue}{\alpha}$$ is a decay term, $$\textcolor{purple}{X[t]}$$ is the input at time $$t$$ and $$\textcolor{brown}{\theta}$$ is the firing threshold. $$\textcolor{orange}{S[t-1]}$$ is the outgoing spike at time $$t-1$$. Note that if there was a spike at the previous timestep $$t-1$$ we subtract the firing threshold from the membrane potential in order to reset it. This is a simple version of the LIF refractory mechanism. The outgoing spike is defined as 

\begin{equation}
\textcolor{orange}{S[t]} = \Theta(\textcolor{ForestGreen}{U[t]} - \textcolor{brown}{\theta})
\label{eq:spike_function}
\end{equation}

where $$\Theta$$ is the heaviside function. In other words, $$\textcolor{orange}{S[t]}$$ is equal to 1 (spike) whenever the membrane potential surpasses threshold and 0 (no spike) otherwise. The heaviside function can be seen in [Figure 2](#fig:surrogate_gradient).

We are going to make one simplification to prevent the math from getting out of control and that is to discard the reset term $$-\textcolor{orange}{S[t]} \textcolor{brown}{\theta}$$. We will add it back at the end, don't worry about it. This is just because the equations get too long. The simplified equation for the neuron's state is now:

\begin{equation}
\textcolor{ForestGreen}{U[t]} = \textcolor{blue}{\alpha} \textcolor{ForestGreen}{U[t-1]} + \textcolor{red}{W_{in}} \textcolor{purple}{X[t]}
\label{eq:lif_simplified}
\end{equation}

We also need to define a loss so we can make meaningful changes with respect to the loss. For simplicity, our loss will simply be the difference between our outgoing spike count $$\textcolor{green}{\hat{y}}$$ and a target spike count $$\textcolor{magenta}{y}$$. Our outgoing spike count $$\textcolor{green}{\hat{y}}$$ is defined as $$\sum_{t=0}^{T} \textcolor{orange}{S[t]}$$. And the loss is defined as follows

\begin{equation}
\textcolor{olive}{E} = \textcolor{green}{\hat{y}} - \textcolor{magenta}{y}
\label{eq:loss}
\end{equation}


Our goal is to find the weight $$\textcolor{red}{W_{in}}$$ that minimizes the loss $$\textcolor{olive}{E}$$. 

## The Gradients

\begin{equation}
\frac{\partial \textcolor{olive}{E}}{\partial \textcolor{red}{W_{in}}} = \frac{\partial \textcolor{green}{\hat{y}}}{\partial \textcolor{red}{W_{in}}} - \frac{\partial \textcolor{magenta}{y}}{\partial \textcolor{red}{W_{in}}}
\label{eq:loss_derivative}
\end{equation}


First of all, $$\frac{\partial \textcolor{magenta}{y}}{\partial \textcolor{red}{W_{in}}} = 0$$, because $$\textcolor{magenta}{y}$$ is the label of this data sample. It has nothing to do with the network weights. However, our network's prediction $$\textcolor{green}{\hat{y}}$$ does depend on $$\textcolor{red}{W_{in}}$$ so let us expand the term to figure out the derivative. Remember that we defined $$\textcolor{green}{\hat{y}} = \sum_{t=0}^{T} \textcolor{orange}{S[t]}$$. So when we we expand it, it looks like this:


$$\textcolor{green}{\hat{y}} = \textcolor{orange}{S[0]} + \textcolor{orange}{S[1]} + ... + \textcolor{orange}{S[T]}$$


$$\frac{\partial \textcolor{green}{\hat{y}}}{\partial \textcolor{red}{W_{in}}} = \frac{\partial \textcolor{orange}{S[0]}}{\partial \textcolor{red}{W_{in}}} + \frac{\partial \textcolor{orange}{S[1]}}{\partial \textcolor{red}{W_{in}}} + ... + \frac{\partial \textcolor{orange}{S[T]}}{\partial \textcolor{red}{W_{in}}}$$


Great, so $$\frac{\partial \textcolor{green}{\hat{y}}}{\partial \textcolor{red}{W_{in}}}$$ is just the sum of the spike derivatives $$\sum_{t=0}^{T} \frac{\partial \textcolor{orange}{S[t]}}{\partial \textcolor{red}{W_{in}}}$$. If we knew what $$\frac{\partial \textcolor{orange}{S[t]}}{\partial \textcolor{red}{W_{in}}}$$ was, we could already find the derivative and be done. Recall that by definition $$\textcolor{orange}{S[t]} = \Theta(\textcolor{ForestGreen}{U[t]} - \textcolor{brown}{\theta})$$. What we have here is a function within a function. The [chain rule](https://en.wikipedia.org/wiki/Differentiation_rules#Chain_rule) tells us how to handle these cases and brings us to:

\begin{equation}
\frac{\partial \textcolor{orange}{S[t]}}{\partial \textcolor{red}{W_{in}}} = \frac{\partial \Theta (\textcolor{ForestGreen}{U[t]} - \textcolor{brown}{\theta})}{\partial (\textcolor{ForestGreen}{U[t]} - \textcolor{brown}{\theta})} \cdot \frac{\partial (\textcolor{ForestGreen}{U[t]} - \textcolor{brown}{\theta})}{\partial \textcolor{red}{W_{in}}}
\label{eq:spike_derivative}
\end{equation}


It's the classic outer derivative times inner derivative. Let's start with the inner derivative on the right. In this simple model, $$\textcolor{brown}{\theta}$$ is just a constant and its derivative is $$0$$. Thus

\begin{equation}
\frac{\partial (\textcolor{ForestGreen}{U[t]} - \textcolor{brown}{\theta})}{\partial \textcolor{red}{W_{in}}} = \frac{\partial (\textcolor{ForestGreen}{U[t]} - 0)}{\partial \textcolor{red}{W_{in}}} = \frac{\partial \textcolor{ForestGreen}{U[t]}}{\partial \textcolor{red}{W_{in}}}
\label{eq:d_s_t_basis}
\end{equation}


So the right part is just the derivative of $$\textcolor{ForestGreen}{U[t]}$$ and the full equation simplifies to

\begin{equation}
\frac{\partial \textcolor{orange}{S[t]}}{\partial \textcolor{red}{W_{in}}} = \frac{\partial \Theta (\textcolor{ForestGreen}{U[t]} - \textcolor{brown}{\theta})}{\partial (\textcolor{ForestGreen}{U[t]} - \textcolor{brown}{\theta})} \cdot \frac{\partial \textcolor{ForestGreen}{U[t]}}{\partial \textcolor{red}{W_{in}}}
\label{eq:d_s_t_simplified}
\end{equation}


We actually have a problem with the left part, because the heaviside function $$\Theta$$ has no proper derivative. 

## Surrogate Gradients

We can estimate the derivative of the heaviside function with the dirac delta function (TODO source), but it's still pretty useless. This is because it's $$0$$ almost everywhere (see figure below), which means this whole equation comes out to $$0$$ most of the time and giving no useful training information.

Instead we use a surrogate gradient function. Intuitively you can think of it like pretending we used a smooth activation function and taking its derivative. The trick is that we didn't actually use a smooth activation function for the forward-pass, but it turns out that the gradient is still useful, even if it didn't come from our original function. You can see this trick in [Figure 2](#fig:surrogate_gradient).

<figure id="fig:surrogate_gradient">
<div id="surrogate-gradient-plot" style="width:100%; height:400px;"></div>
<figcaption><strong>Figure 2:</strong> Surrogate gradient concept showing the Heaviside function (left, solid) and its smooth sigmoid approximation (left, dashed), along with their derivatives (right). The Heaviside derivative is the Dirac delta (spike at zero), while the sigmoid derivative provides a smooth, trainable gradient. Note this may not be a technically accurate representation of the Dirac delta.</figcaption>
</figure>

<script src="https://cdn.plot.ly/plotly-2.35.2.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', function() {
    const sigmoidColor = '#1f77b4'; // Muted blue
    const heavisideColor = '#ff7f0e'; // Safety orange

    // Generate data
    const x = [];
    for (let i = -5; i <= 5; i += 0.1) {
        x.push(i);
    }

    // Left plot data
    const y_heaviside = x.map(val => val < 0 ? 0 : 1);
    const y_sigmoid = x.map(val => 1 / (1 + Math.exp(-val)));

    // Right plot data
    const y_sigmoid_deriv = y_sigmoid.map(val => val * (1 - val));

    // Traces for the left plot
    const trace_heaviside = {
        x: x,
        y: y_heaviside,
        mode: 'lines',
        name: 'Heaviside (Θ)',
        line: { color: heavisideColor, width: 3 },
        showlegend: false
    };

    const trace_sigmoid = {
        x: x,
        y: y_sigmoid,
        mode: 'lines',
        name: 'Sigmoid (σ, Surrogate)',
        line: { color: sigmoidColor, dash: 'dash', width: 3 },
        showlegend: false
    };

    // Traces for the right plot
    const trace_dirac = {
        x: [0, 0],
        y: [0, 1], // Representing Dirac as a spike of height 1
        mode: 'lines',
        name: 'Dirac Delta (δ)',
        xaxis: 'x2',
        yaxis: 'y2',
        line: { color: heavisideColor, width: 3 }
    };

    const trace_sigmoid_deriv = {
        x: x,
        y: y_sigmoid_deriv,
        mode: 'lines',
        name: 'Sigmoid Derivative (σ′)',
        xaxis: 'x2',
        yaxis: 'y2',
        line: { color: sigmoidColor, dash: 'dash', width: 3 }
    };

    const layout = {
        title: 'Surrogate Gradient Concept',
        xaxis: {
            domain: [0, 0.45],
            title: 'x',
            zeroline: true
        },
        yaxis: {
            title: 'f(x)',
            range: [-0.1, 1.1]
        },
        xaxis2: {
            domain: [0.55, 1],
            title: 'x',
            zeroline: true
        },
        yaxis2: {
            anchor: 'x2',
            title: 'f\'(x)',
            range: [-0.1, 1.1]
        },
        legend: {
            x: 1.02,
            xanchor: 'left',
            y: 0.5,
            yanchor: 'middle',
            orientation: 'v'
        },
        margin: {
            b: 100,
            r: 150
        }
    };

    Plotly.newPlot('surrogate-gradient-plot', [trace_heaviside, trace_sigmoid, trace_dirac, trace_sigmoid_deriv], layout);
});
</script>

Let's use the sigmoid derivative as our surrogate gradient function, i.e., $$\frac{\partial \Theta (\textcolor{ForestGreen}{U[t]} - \textcolor{brown}{\theta})}{\partial (\textcolor{ForestGreen}{U[t]} - \textcolor{brown}{\theta})} \approx \sigma'(\textcolor{ForestGreen}{U[t]} - \textcolor{brown}{\theta})$$. We will treat it as a known quantity. $$\textcolor{brown}{\theta}$$ is just a constant and $$\textcolor{ForestGreen}{U[t]}$$ is known at time $$t$$ so we now know the left side of equation 8. All that's left is $$\frac{\partial \textcolor{ForestGreen}{U[t]}}{\partial \textcolor{red}{W_{in}}}$$.

To find the derivative of $$\textcolor{ForestGreen}{U[t]}$$, let's remember its definition: $$\textcolor{ForestGreen}{U[t]} = \textcolor{blue}{\alpha} \textcolor{ForestGreen}{U[t-1]} + \textcolor{red}{W_{in}} \textcolor{purple}{X[t]}$$. Since $$\textcolor{ForestGreen}{U[t]}$$ depends on $$\textcolor{red}{W_{in}}$$ and obviously $$\textcolor{red}{W_{in}} \textcolor{purple}{X[t]}$$ depends on $$\textcolor{red}{W_{in}}$$ as well, we get two parts to the derivative:


$$\frac{\partial \textcolor{ForestGreen}{U[t]}}{\partial \textcolor{red}{W_{in}}} = \frac{\partial (\textcolor{blue}{\alpha} \textcolor{ForestGreen}{U[t-1]})}{\partial \textcolor{red}{W_{in}}} + \frac{\partial (\textcolor{red}{W_{in}} \textcolor{purple}{X[t]})}{\partial \textcolor{red}{W_{in}}}$$


Once again, $$\textcolor{blue}{\alpha}$$ is a constant, so the first term comes out to $$\textcolor{blue}{\alpha} \frac{\partial \textcolor{ForestGreen}{U[t-1]}}{\partial \textcolor{red}{W_{in}}}$$. For the second term, obviously the derivative with respect to $$\textcolor{red}{W_{in}}$$ is simply $$\frac{\partial (\textcolor{red}{W_{in}} \textcolor{purple}{X[t]})}{\partial \textcolor{red}{W_{in}}} = \textcolor{purple}{X[t]}$$

And thus the derivative of $$\textcolor{ForestGreen}{U[t]}$$ is:

\begin{equation}
\frac{\partial \textcolor{ForestGreen}{U[t]}}{\partial \textcolor{red}{W_{in}}} = \textcolor{blue}{\alpha} \frac{\partial \textcolor{ForestGreen}{U[t-1]}}{\partial \textcolor{red}{W_{in}}} + \textcolor{purple}{X[t]}
\label{eq:membrane_derivative_recursive}
\end{equation}


Okay that was straight-forward but now we have a weird recursion because $$\frac{\partial \textcolor{ForestGreen}{U[t]}}{\partial \textcolor{red}{W_{in}}}$$ depends on $$\frac{\partial \textcolor{ForestGreen}{U[t-1]}}{\partial \textcolor{red}{W_{in}}}$$. That one depends on $$\frac{\partial \textcolor{ForestGreen}{U[t-2]}}{\partial \textcolor{red}{W_{in}}}$$ and so on. The recursion ends when we reach the initial state, so let's start there.

## Solving the recursion


The goal is to find the pattern in this recursion and then take its derivative. It will only take a couple of steps, but first let's set an initial state $$\textcolor{ForestGreen}{U[0]} = 0$$ and hence $$\frac{\partial \textcolor{ForestGreen}{U[0]}}{\partial \textcolor{red}{W_{in}}} = 0$$. By definition (equation 3) we know that:


$$\textcolor{ForestGreen}{U[1]} = \textcolor{blue}{\alpha} \textcolor{ForestGreen}{U[0]} + \textcolor{red}{W_{in}} \textcolor{purple}{X[0]}$$


$$ = \textcolor{blue}{\alpha} 0 + \textcolor{red}{W_{in}} \textcolor{purple}{X[1]} $$

$$ = \textcolor{red}{W_{in}} \textcolor{purple}{X[1]} $$


Going one step further, we find that: 


$$\textcolor{ForestGreen}{U[2]} = \textcolor{blue}{\alpha} \textcolor{ForestGreen}{U[1]} + \textcolor{red}{W_{in}} \textcolor{purple}{X[2]}$$


$$= \textcolor{blue}{\alpha} (\textcolor{red}{W_{in}} \textcolor{purple}{X[1]}) + \textcolor{red}{W_{in}} \textcolor{purple}{X[2]}$$


$$= \textcolor{blue}{\alpha} \textcolor{red}{W_{in}} \textcolor{purple}{X[1]} + \textcolor{red}{W_{in}} \textcolor{purple}{X[2]}$$


and another step:


$$\textcolor{ForestGreen}{U[3]} = \textcolor{blue}{\alpha} \textcolor{ForestGreen}{U[2]} + \textcolor{red}{W_{in}} \textcolor{purple}{X[3]}$$


$$ = \textcolor{blue}{\alpha} (\textcolor{blue}{\alpha} \textcolor{red}{W_{in}} \textcolor{purple}{X[1]} + \textcolor{red}{W_{in}} \textcolor{purple}{X[2]}) + \textcolor{red}{W_{in}} \textcolor{purple}{X[3]}$$


$$ = \textcolor{blue}{\alpha}^2 \textcolor{red}{W_{in}} \textcolor{purple}{X[1]} + \textcolor{blue}{\alpha} \textcolor{red}{W_{in}} \textcolor{purple}{X[2]} + \textcolor{red}{W_{in}} \textcolor{purple}{X[3]}$$


To make the pattern more obvious, let me add some exponents: 


$$\textcolor{ForestGreen}{U[3]} = \textcolor{blue}{\alpha}^2 \textcolor{red}{W_{in}} \textcolor{purple}{X[1]} + \textcolor{blue}{\alpha}^1 \textcolor{red}{W_{in}} \textcolor{purple}{X[2]} + \textcolor{blue}{\alpha}^0 \textcolor{red}{W_{in}} \textcolor{purple}{X[3]}$$


In general, we find that


$$\textcolor{ForestGreen}{U[t]} = \textcolor{blue}{\alpha}^{t-1} \textcolor{red}{W_{in}} \textcolor{purple}{X[1]} + \textcolor{blue}{\alpha}^{t-2} \textcolor{red}{W_{in}} \textcolor{purple}{X[2]} + ... + \textcolor{blue}{\alpha}^{t-t} \textcolor{red}{W_{in}} \textcolor{purple}{X[t]}$$

$$ = \sum_{i=1}^{t} \textcolor{blue}{\alpha}^{t-i} \textcolor{red}{W_{in}} \textcolor{purple}{X[i]}$$


Since the derivative of the sum is just the sum of the derivatives, we get the following equation:

\begin{equation}
\frac{\partial \textcolor{ForestGreen}{U[t]}}{\partial \textcolor{red}{W_{in}}} = \sum_{i=1}^{t} \textcolor{blue}{\alpha}^{t-i} \textcolor{purple}{X[i]}
\label{eq:membrane_derivative_closed}
\end{equation}

## Putting it all together
To recap, we were trying to find the following derivative:

\begin{equation}
\frac{\partial \textcolor{olive}{E}}{\partial \textcolor{red}{W_{in}}} = \frac{\partial \textcolor{olive}{E}}{\partial \textcolor{green}{\hat{y}}} \cdot \frac{\partial \textcolor{green}{\hat{y}}}{\partial \textcolor{red}{W_{in}}}
\end{equation}

Expanding $$\frac{\partial \textcolor{green}{\hat{y}}}{\partial \textcolor{red}{W_{in}}}$$ using the chain rule through the spikes and membrane potentials:

\begin{equation}
\frac{\partial \textcolor{olive}{E}}{\partial \textcolor{red}{W_{in}}} = \frac{\partial \textcolor{olive}{E}}{\partial \textcolor{green}{\hat{y}}} \cdot \sum_{t=0}^T \left[\frac{\partial \textcolor{orange}{S[t]}}{\partial \textcolor{ForestGreen}{U[t]}} \cdot \frac{\partial \textcolor{ForestGreen}{U[t]}}{\partial \textcolor{red}{W_{in}}}\right]
\end{equation}

And we were able to resolve it to this:


\begin{equation}
\frac{\partial \textcolor{olive}{E}}{\partial \textcolor{red}{W_{in}}} = \sum_{t=0}^{T} \sigma'(\textcolor{ForestGreen}{U[t]} - \textcolor{brown}{\theta}) \cdot \sum_{i=1}^{t} \textcolor{blue}{\alpha}^{t-i} \textcolor{purple}{X[i]}
\label{eq:final_gradient}
\end{equation}


So that's all the computations for the single neuron when we disregard the reset term. Let's add that back.

## The reset term
The reset term is part of $$\frac{\partial \textcolor{ForestGreen}{U[t]}}{\partial \textcolor{red}{W_{in}}}$$. As per equation \ref{eq:lif_full}, it is a term that gets subtracted from the membrane potential: $$-\textcolor{orange}{S[t-1]}\textcolor{brown}{\theta}$$.

The derivative is $$\frac{\partial (-\textcolor{orange}{S[t-1]}\textcolor{brown}{\theta})}{\partial \textcolor{red}{W_{in}}}$$ and we already know how to compute it for the case of $$\textcolor{orange}{S[t]}$$. We can now extend equation \ref{eq:membrane_derivative_closed} to include the reset term:

\begin{equation}
\frac{\partial \textcolor{ForestGreen}{U[t]}}{\partial \textcolor{red}{W_{in}}} = \sum_{i=1}^{t} \textcolor{blue}{\alpha}^{t-i} \textcolor{purple}{X[i]} - \textcolor{brown}{\theta} \frac{\partial (\textcolor{orange}{S[t-1]})}{\partial \textcolor{red}{W_{in}}}
\end{equation}

We already know how to compute $$\frac{\partial \textcolor{orange}{S[t-1]}}{\partial \textcolor{red}{W_{in}}}$$ from our earlier derivation (just shift the time index):

\begin{equation}
\frac{\partial \textcolor{orange}{S[t-1]}}{\partial \textcolor{red}{W_{in}}} = \sigma'(\textcolor{ForestGreen}{U[t-1]} - \textcolor{brown}{\theta}) \cdot \sum_{i=1}^{t-1} \textcolor{blue}{\alpha}^{t-1-i} \textcolor{purple}{X[i]}
\end{equation}

Substituting this into the full gradient, we get the complete version of equation \ref{eq:final_gradient} with the reset term included:

\begin{equation}
\frac{\partial \textcolor{olive}{E}}{\partial \textcolor{red}{W_{in}}} = \sum_{t=0}^{T} \sigma'(\textcolor{ForestGreen}{U[t]} - \textcolor{brown}{\theta}) \cdot \left[\sum_{i=1}^{t} \textcolor{blue}{\alpha}^{t-i} \textcolor{purple}{X[i]} - \textcolor{brown}{\theta} \sigma'(\textcolor{ForestGreen}{U[t-1]} - \textcolor{brown}{\theta}) \cdot \sum_{j=1}^{t-1} \textcolor{blue}{\alpha}^{t-1-j} \textcolor{purple}{X[j]}\right]
\label{eq:final_gradient_with_reset}
\end{equation}

If you are like me then this has become a complete mess to you. Henceforth let's work with the more abstract version from equation 12, which did capture the reset term on an abstract level.

## Generalizing to multiple layers (WIP wtf did i do here?)

Let's extend our simple neuron setup to include a second layer, as shown in [Figure 3](#fig:two_layer_network).

<figure id="fig:two_layer_network">
<div id="two-layer-network-diagram" style="width: 100%; margin: 2em auto;"></div>
<figcaption><strong>Figure 3:</strong> Two-layer network showing the weight transport problem. The first neuron (U₀[t]) produces spikes S₀[t] that connect to the second neuron (U₁[t]) through weight W<sub>rec</sub>, which then produces the final spike output S₁[t].</figcaption>
</figure>

<script src="{{ '/assets/js/two-layer-diagram.js' | relative_url }}"></script>

Unfortunately we have to index our neurons now. As a computer scientist I am unable to use anything but $$0$$ for the first neuron and subscript $$1$$ for the second. 

Now our equation is much the same as it was, but there's some additional parts. Our goal is still to find the gradient for $$\textcolor{red}{W_{in}}$$ and I will outline the path here:

$$ \Delta \textcolor{red}{W_{in}} = \frac{\partial \textcolor{olive}{E}}{\partial \textcolor{red}{W_{in}}}$$


We used to have


$$ \Delta \textcolor{red}{W_{in}} = \frac{\partial \textcolor{olive}{E}}{\partial \textcolor{orange}{S_0[t]}} \frac{\partial \textcolor{orange}{S_0[t]}}{\partial \textcolor{red}{W_{in}}}$$


Now $$\frac{\partial \textcolor{olive}{E}}{\partial \textcolor{orange}{S_0[t]}}$$ depends on the spikes of the layer before 


$$ \Delta \textcolor{red}{W_{in}} = \frac{\partial \textcolor{olive}{E}}{\partial \textcolor{orange}{S_1[t]}} \frac{\partial \textcolor{orange}{S_1[t]}}{\partial \textcolor{orange}{S_0[t]}} \frac{\partial \textcolor{orange}{S_0[t]}}{\partial \textcolor{red}{W_{in}}}$$


The last term $$\frac{\partial \textcolor{orange}{S_0[t]}}{\partial \textcolor{red}{W_{in}}}$$ is one that we already derived above. We also kind of know $$\frac{\partial \textcolor{olive}{E}}{\partial \textcolor{orange}{S_1[t]}}$$ because it's the same as we did for $$\textcolor{orange}{S_0[t]}$$ just with the spikes of the second layer instead of the first.

All that's left is $$\frac{\partial \textcolor{orange}{S_1[t]}}{\partial \textcolor{orange}{S_0[t]}}$$. The second LIF's spike activation and derivative are identical to the first except for indices

\begin{equation}
\textcolor{orange}{S_1[t]} = \Theta(\textcolor{ForestGreen}{U_1[t]} - \textcolor{brown}{\theta})
\label{eq:second_spike_function}
\end{equation}

\begin{equation}
\frac{\partial \textcolor{orange}{S_1[t]}}{\partial \textcolor{orange}{S_0[t]}} = \sigma'(\textcolor{ForestGreen}{U_1[t]} - \textcolor{brown}{\theta}) \cdot \frac{\partial \textcolor{ForestGreen}{U_1[t]}}{\partial \textcolor{orange}{S_0[t]}}
\label{eq:second_spike_function_derivative}
\end{equation}


So now we just need to resolve $$\textcolor{ForestGreen}{U_1[t]}$$ and its derivative and we are done


\begin{equation}
\textcolor{ForestGreen}{U_1[t]} = \textcolor{blue}{\alpha} \textcolor{ForestGreen}{U_1[t-1]} + \textcolor{red}{W_{rec}} \textcolor{orange}{S_0[t]}
\label{eq:second_membrane_potential}
\end{equation}


\begin{equation}
\frac{\partial \textcolor{ForestGreen}{U_1[t]}}{\partial \textcolor{orange}{S_0[t]}} = \textcolor{blue}{\alpha} \frac{\partial \textcolor{ForestGreen}{U_1[t-1]}}{\partial \textcolor{orange}{S_0[t]}} + \textcolor{red}{W_{rec}}
\label{eq:second_membrane_potential_derivative}
\end{equation} 


## Dealing with recurrent weights
WIP