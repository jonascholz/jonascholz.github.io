---
title: 'Implementing a LIF in JAX (WIP)'
excerpt: "We code up a simple LIF implementation in JAX. Make sure to read the theory first. [Read more](/posts/2025/10/lif-jax/)<br/><img src='/assets/images/lif_jax.png'>"
date: 2025-10-26
permalink: /posts/2025/10/lif-jax/
tags:
  - JAX
  - SNN
  - Tutorial
  - LIF
---

In the [last tutorial](/posts/2025/10/lif-theory/) we looked at the theory of implementing a LIF neuron. Now we will put it into code with JAX.

If you are unfamiliar with JAX, you can think of it as a fancy numpy for the scope of this tutorial. In the future we will see that it also does autodiff and other things.

## Quick refresher
As we recall, the LIF's state $$\textcolor{ForestGreen}{U[t]}$$ is governed by the following equation:

$$
\begin{aligned}
\textcolor{ForestGreen}{U[t]} &= \underbrace{\textcolor{blue}{\alpha} \textcolor{ForestGreen}{U[t-1]}}_{\text{decayed state}} + \underbrace{\textcolor{red}{W} \textcolor{purple}{X[t]}}_{\text{weighted input}} - \underbrace{\textcolor{orange}{S[t-1]} \textcolor{brown}{\theta}}_{\text{reset}}
\end{aligned}
$$

Additionally, the firing mechanism is defined as:

$$
\textcolor{orange}{S[t]} = \underbrace{\Theta}_{\text{heaviside}}(\textcolor{ForestGreen}{U[t]} - \textcolor{brown}{\theta})
$$

## The basic architecture
LIFs have a state, which changes at every timestep. They also have some parameters, such as their decay constant, which don't change as often.

We need to track the state and the parameters somehow. We will also need a way to integrate inputs and calculate the next state. Let's draw these three distinct parts and call it an architecture.

<figure id="fig:lif_architecture">
<div id="lif-architecture-diagram" style="width: 100%; margin: 2em auto;"></div>
<figcaption><strong>Figure 1:</strong> LIF neuron architecture showing the separation between parameters (decay α, weight w, threshold θ), state (membrane potential u[t] and spike output s[t]), and the step function that processes inputs.</figcaption>
</figure>

<script src="{{ '/assets/js/lif-architecture-diagram.js' | relative_url }}"></script>

JAX is built around pure functions. In other programming languages you think of neurons as objects that change over time. In JAX there is no such thing. Instead we run a function on a state to receive a new state. Importantly, the function doesn't keep track of anything, it just transforms one state to another. Avoiding side-effects makes a function pure and it goes against much of modern object-oriented programming.

## Putting it into code
Let's start with the parameters that define our LIFs. There will be more than one LIF in our layer and each one has its own decay constant $$\textcolor{blue}{\alpha}$$. There is a shared weight matrix $$\textcolor{red}{W}$$, which gives us the incoming weights for every neuron. Finally, we also have the threshold $$\textcolor{brown}{\theta}$$.

```python
from typing import NamedTuple
from jax import Array
import jax.numpy as jnp

class LIFParams(NamedTuple):
    alpha: Array
    W: Array
    theta: Array
```

There is some significance in JAX to using so-called PyTrees like the NamedTuple. These are just objects such as lists or tuples that can easily be traversed, which will be important for vectorization and gradients.

If you are unfamiliar with NamedTuples, here's an example of initializing our LIFParams:

```python
import jax.numpy as jnp

# assuming 2 neurons with 2 inputs each
alpha = jnp.array([0.9, 0.9]) 
W = jnp.array([[0.5, -0.2], [0.3, 0.8]])
theta = jnp.array([1.0, 1.0])
params = LIFParams(alpha, W, theta)
print(params)
```
```console
LIFParams(alpha=Array([0.9, 0.9], dtype=float32), W=Array([[ 0.5, -0.2],
       [ 0.3,  0.8]], dtype=float32), theta=Array([1., 1.], dtype=float32))
```

Note that we have assumed here that the layer consists of 2 neurons and each one takes 2 inputs. As a result, the $$\textcolor{blue}{\alpha}$$ and $$\textcolor{brown}{\theta}$$ are 2-dimensional vectors, and $$\textcolor{red}{W}$$ is a 2x2 matrix.

These parameters don't change during inference, but the state does. Let's implement it.

```python
class LIFState(NamedTuple):
    u: Array
    spike: Array

u = jnp.zeros(2, dtype=jnp.float32)
spike = jnp.zeros(2, dtype=jnp.float32)
state = LIFState(u, spike)
print(state)
```
```console
LIFState(u=Array([0., 0.], dtype=float32), spike=Array([0., 0.], dtype=float32))
```

So now we have the membrane potential U[t] and whether or not each neuron spikes S[t]. Looking back at Figure 1, we only need a function to update the neurons state now.

```python
def lif_step(
    params: LIFParams,
    state: LIFState,
    inputs: jnp.ndarray,
):
    decayed_state = params.alpha * state.u
    weighted_input = inputs @ params.W
    reset = state.spike * params.theta
    u_new = decayed_state + weighted_input - reset
    spike = jnp.heaviside(u_new - params.v_thresh)

    return LIFState(u=u_new, spike=spike)
```

We take in the new input and the state, as well as the parameters. From this we calculate the next state. Great, let's use it. 

```python
inputs = jnp.array([1, 0])
new_state = lif_step(params, state, inputs)
print(new_state)
```
```console
LIFState(u=Array([ 0.5, -0.2], dtype=float32), spike=Array([0., 0.], dtype=float32))
```

It works! Now let's see how it behaves when we generate some random spikes with a probability of 10% and watch the state.

```python
current_state = LIFState(u=jnp.array([0.0]), spike=jnp.array([0.0]))
key = random.PRNGKey(3)
n_steps = 100
inputs = random.bernoulli(key, p=0.15, shape=(n_steps, 1))

# NOTE this is an inefficient way of doing it, we will improve it shortly
state_history = []
for i in range(n_steps):
    current_state = lif_step(params, current_state, inputs[i])
    state_history.append(current_state)
```

Okay so we have a history of states. You can prompt an LLM of your choice to plot that, or you can use my function, which also comes from an LLM:

```python
def plot_lif_simulation(state_history, inputs, params: LIFParams, filename: str = 'lif_simulation.svg'):
    """
    Create a 3-part plot showing:
    1. Membrane potential over time
    2. Incoming spikes
    3. Outgoing spikes

    Args:
        state_history: List of LIFState objects
        inputs: Array of input spikes (n_steps, n_inputs)
        params: LIFParams containing theta for threshold line
        filename: Output filename for the plot
    """
    # Extract data for plotting
    u_history = jnp.array([s.u[0] for s in state_history])
    spike_history = jnp.array([s.spike[0] for s in state_history])
    input_spikes = inputs.squeeze()
    n_steps = len(state_history)

    # Create 3-part plot with aligned time axes
    _, axes = plt.subplots(3, 1, figsize=(12, 8), sharex=True)
    time_steps = jnp.arange(n_steps)

    # Plot membrane potential
    axes[0].plot(time_steps, u_history, 'b-', linewidth=1.5)
    axes[0].axhline(y=params.theta[0], color='r', linestyle='--', label='Threshold')
    axes[0].set_ylabel('Membrane Potential (u)', fontsize=11)
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)

    # Plot incoming spikes
    axes[1].axhline(y=0, color='gray', linewidth=1, alpha=0.7)
    spike_times_in = time_steps[input_spikes > 0]
    axes[1].vlines(spike_times_in, 0, 0.8, colors='green', linewidths=2)
    axes[1].set_ylabel('Incoming Spikes', fontsize=11)
    axes[1].set_ylim([-0.1, 1])
    axes[1].set_yticks([])
    axes[1].spines['top'].set_visible(False)
    axes[1].spines['right'].set_visible(False)
    axes[1].spines['left'].set_visible(False)
    axes[1].grid(True, alpha=0.3, axis='x')

    # Plot outgoing spikes
    axes[2].axhline(y=0, color='gray', linewidth=1, alpha=0.7)
    spike_times_out = time_steps[spike_history > 0]
    axes[2].vlines(spike_times_out, 0, 0.8, colors='red', linewidths=2)
    axes[2].set_ylabel('Outgoing Spikes', fontsize=11)
    axes[2].set_xlabel('Time Step', fontsize=11)
    axes[2].set_ylim([-0.1, 1])
    axes[2].set_yticks([])
    axes[2].spines['top'].set_visible(False)
    axes[2].spines['right'].set_visible(False)
    axes[2].spines['left'].set_visible(False)
    axes[2].grid(True, alpha=0.3, axis='x')

    plt.tight_layout()
    plt.savefig(filename, dpi=150, bbox_inches='tight')
    print(f"Plot saved to {filename}")
    plt.show()
```

<figure id="fig:lif_simulation">
<img src="/assets/images/lif_simulation.svg" alt="LIF Simulation" style="width: 100%; max-width: 850px; margin: 2em auto; display: block;">
<figcaption><strong>Figure 2:</strong> LIF neuron simulation over 100 time steps showing the membrane potential (top), incoming spikes (middle), and outgoing spikes (bottom). The dashed red line indicates the firing threshold.</figcaption>
</figure>

Looks about right. Now we just have to optimize it a little and we can call it a day.

## Optimizing with the scan method
WIP

## Optional: Multi-layer networks
WIP