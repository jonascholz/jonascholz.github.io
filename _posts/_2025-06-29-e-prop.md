---
title: 'Key points of e-prop (WIP)'
date: 2025-06-28
permalink: /posts/2025/06/e-prop/
tags:
  - JAX
  - SNN
  - Tutorial
  - e-prop
---

e-prop is a local learning rule that calculates eligbility traces for every parameter based on only local information. These traces are combines with a learning signal to change weights.

In this post we will figure out what i calculates and why. I'll do a quick explanation of how the rule works, but if you get the general idea you can just skip the next section. And of course, here's the link to the original paper by Bellec et al. [https://www.nature.com/articles/s41467-020-17236-y](https://www.nature.com/articles/s41467-020-17236-y).

## The general idea
WIP

## The actual equations
(TODO neuron equation from bptt) (TODO explain that we are dropping the reset term once again) We are going to distinguish between input connections, output connections and recurrent connections. For input connections, let's assume once again assume we only have one recurrent neuron with one input connection, as shown in [Figure 1](#fig:eprop_neuron_diagram).

<figure id="fig:eprop_neuron_diagram">
<style>
.e-prop-diagram {
    display: flex;
    align-items: center;
    justify-content: center;
    gap: 15px;
    margin: 2em auto;
    font-family: monospace;
    font-size: 1.1em;
    width: 100%;
    text-align: center;
}
.neuron-circle {
    width: 60px;
    height: 60px;
    border-radius: 50%;
    border: 2px solid #333;
    display: flex;
    align-items: center;
    justify-content: center;
}
.connection-arrow {
    position: relative;
    width: 80px;
    height: 2px;
    background-color: #333;
}
.connection-arrow::after {
    content: '';
    position: absolute;
    right: -1px;
    top: -4px;
    width: 0;
    height: 0;
    border-top: 5px solid transparent;
    border-bottom: 5px solid transparent;
    border-left: 10px solid #333;
}
.connection-label {
    position: absolute;
    width: 100%;
    text-align: center;
    top: -2.5em;
    font-style: italic;
}
</style>
<div class="e-prop-diagram">
    <span style="color: purple; font-weight: bold;">X[t]</span>
    <div class="connection-arrow">
        <div class="connection-label">$\textcolor{red}{W_{in}}$</div>
    </div>
    <div class="neuron-circle" style="color: ForestGreen; font-weight: bold;">U[t]</div>
    <div class="connection-arrow"></div>
    <span style="color: orange; font-weight: bold;">S[t]</span>
</div>
<figcaption><strong>Figure 1:</strong> Simple neuron setup for e-prop analysis with input X[t], membrane potential U[t], input weight W<sub>in</sub>, and output spike S[t].</figcaption>
</figure>


Normally if we were doing backpropagation through time (BPTT), our weight update would be like this

\begin{equation}
\Delta \textcolor{red}{W_{in}} = -\eta \frac{\partial \textcolor{olive}{E}}{\partial \textcolor{red}{W_{in}}}
\label{eq:basic_weight_update}
\end{equation}

in other words, we would see how the loss function $$\textcolor{olive}{E}$$ changes when we change the weight $$\textcolor{red}{W_{in}}$$. Then we just have to adjust $$\textcolor{red}{W_{in}}$$ in the direction that decreases the loss. We can expand this term into two different derivatives:

\begin{equation}
\Delta \textcolor{red}{W_{in}} = -\eta \sum_{t} \frac{\partial \textcolor{olive}{E}}{\partial \textcolor{orange}{S[t]}} \frac{\partial \textcolor{orange}{S[t]}}{\partial \textcolor{red}{W_{in}}}
\label{eq:expanded_weight_update}
\end{equation}

In other words, we see how the loss changes with respect to the outgoing spikes and how these spikes change with respect to the weight. There's a sum because the spikes at every timestep are factored in when using BPTT. Now the key insight of e-prop is that you can compute these two derivatives separately. Let's give them some names:

\begin{equation}
\Delta \textcolor{red}{W_{in}} = -\eta \sum_{t} \frac{\partial \textcolor{olive}{E}}{\partial \textcolor{orange}{S[t]}} \frac{\partial \textcolor{orange}{S[t]}}{\partial \textcolor{red}{W_{in}}}
\label{eq:eprop_decomposition}
\end{equation}
 

The decomposition in \eqref{eq:eprop_decomposition} leads us to the key insight of e-prop: the right term can we computed locally. The left side will be called the learning signal, or formally 

\begin{equation}
\textcolor{teal}{L[t]} = \frac{\partial \textcolor{olive}{E}}{\partial \textcolor{orange}{S[t]}}
\label{eq:L_signal}
\end{equation}

The right side is called the eligibility trace 

\begin{equation}
\textcolor{cyan}{e[t]} = \frac{\partial \textcolor{orange}{S[t]}}{\partial \textcolor{red}{W_{in}}}. 
\label{eq:e_trace}
\end{equation}

So the full equation can we obfuscated into these two parts:

\begin{equation}
\Delta \textcolor{red}{W_{in}} = -\eta \sum_{t} (\textcolor{teal}{L[t]} \textcolor{cyan}{e[t]})
\label{eq:eprop_decomposition_obfuscated}
\end{equation}
 

The eligibility trace is the thing we can compute locally. If you have read the backprop tutorial (TODO link), you may remember $$\frac{\partial \textcolor{orange}{S[t]}}{\partial \textcolor{red}{W_{in}}}$$ as $$\textcolor{orange}{S'[t]}$$. Well, it's the same thing: $$\textcolor{cyan}{e[t]} = \textcolor{orange}{S'[t]}$$ We already know its derivative:

\begin{equation}
\textcolor{orange}{S'[t]} = \Theta'(\textcolor{ForestGreen}{U[t]} - \textcolor{brown}{\theta}) \cdot \textcolor{ForestGreen}{U'[t]}
\label{eq:S_t_derivative}
\end{equation}


It required the derivative of $$\textcolor{ForestGreen}{U'[t]}$$ which was simply:

\begin{equation}
\textcolor{ForestGreen}{U'[t]} = \sum_{i=1}^{t} \textcolor{blue}{\alpha}^{t-i} \textcolor{purple}{X[i]}
\label{eq:U_t_derivative}
\end{equation}


and we defined $$\Theta'$$ as the surrogate gradient of the heaviside function. For illustrative purposes we used the derivative of the sigmoid function $$\sigma'$$. So if we plug \eqref{eq:U_t_derivative} into \eqref{eq:S_t_derivative} we get the following:

$$\textcolor{cyan}{e[t]} = \Theta'(\textcolor{ForestGreen}{U[t]} - \textcolor{brown}{\theta}) \cdot \textcolor{ForestGreen}{U'[t]}$$

\begin{equation}
\textcolor{cyan}{e[t]} = \Theta'(\textcolor{ForestGreen}{U[t]} - \textcolor{brown}{\theta}) \cdot \sum_{i=1}^{t} \textcolor{blue}{\alpha}^{t-i} \textcolor{purple}{X[i]}
\label{eq:e_t_unrolled}
\end{equation}

Okay, almost there. Now we just have to find the learning signal $$\textcolor{teal}{L}$$. This is the derivative of the loss function with respect to the spikes, so it depends on the loss function. In the case of a regression problem it could look like this:

\begin{equation}
\textcolor{olive}{E} = \frac{1}{2} \sum_t (\textcolor{magenta}{y[t]} - \textcolor{green}{\hat{y}[t]})^2
\label{eq:regression_loss}
\end{equation}

where $$\textcolor{green}{\hat{y}}$$ is our prediction. In the simplest case, it's just the sum of all spikes $$\sum_t \textcolor{orange}{S[t]}$$. To find the derivative of $$\textcolor{olive}{E}$$ with respect to $$\textcolor{orange}{S[t]}$$ let's first rewrite the equation

\begin{equation}
\textcolor{olive}{E} = \frac{1}{2} \sum_t (\textcolor{magenta}{y[t]} - \sum_t \textcolor{orange}{S[t]})^2
\label{eq:regression_unrolled}
\end{equation}

And the learning signal is the derivative of $$\textcolor{olive}{E}$$ with respect to $$\textcolor{orange}{S[t]}$$. Our equation is of the form $$\frac{1}{2}x^2$$ and whenever x is not a constant, the derivative comes out $$2\frac{1}{2}x = x$$.

\begin{equation}
\frac{\partial \textcolor{olive}{E}}{\partial \textcolor{orange}{S[t]}} = (\sum_t (\textcolor{magenta}{y[t]} - \sum_t \textcolor{orange}{S[t]}))'
\label{eq:regression_unrolled_inner}
\end{equation}

So now we need to find the derivative of that inner part with respect to $$\textcolor{orange}{S[t]}$$. Starting with what we know, the derivative of $$\textcolor{orange}{S[t]}$$ with respect to $$\textcolor{orange}{S[t]}$$ is just 1. However, for all the prior points in the sum such as $$\textcolor{orange}{S[t-1]}$$ the derivative is $$0$$ because $$\textcolor{orange}{S[t-1]}$$ doesn't depend on $$\textcolor{orange}{S[t]}$$. In other words


$$\frac{\partial \sum_t \textcolor{orange}{S[t]}}{\partial \textcolor{orange}{S[t]}} = \frac{\partial \textcolor{orange}{S[0]}}{\partial \textcolor{orange}{S[t]}} +  \frac{\partial \textcolor{orange}{S[1]}}{\partial \textcolor{orange}{S[t]}} + ... +  \frac{\partial \textcolor{orange}{S[t-1]}}{\partial \textcolor{orange}{S[t]}} +  \frac{\partial \textcolor{orange}{S[t]}}{\partial \textcolor{orange}{S[t]}}$$

$$ = 0 + 0 + ... + 0 + 1 $$

$$ = 1 $$

Also $$\textcolor{magenta}{y[t]}$$, which is the label at timestep $$t$$, doesn't depend on $$\textcolor{orange}{S[t]}$$, making its derivative $$0$$. We can rewrite the equation as


$$\frac{\partial \textcolor{olive}{E}}{\partial \textcolor{orange}{S[t]}} = (\sum_t (\textcolor{magenta}{y'[t]} - 1))$$


$$= \sum_t (0 - 1)$$

and thus

\begin{equation}
L[t] = -t
\label{eq:learning_signal_solved}
\end{equation}

Strangely enough, for our single neuron the learning signal is $$-t$$ at every timestep $t$.

## Putting it all together
We set out to find $\Delta W_{in}$ which \eqref{eq:eprop_decomposition_obfuscated} defined as 


$$\Delta \textcolor{red}{W_{in}} = -\eta \sum_{t} (\textcolor{teal}{L[t]} \textcolor{cyan}{e[t]})$$


We have identified that $\textcolor{teal}{L[t]}$ is just 


$$\textcolor{teal}{L[t]} = -t$$


and $\textcolor{cyan}{e[t]}$ although a bit longer is simple enough to evaluate


$$\textcolor{cyan}{e[t]} = \Theta'(\textcolor{ForestGreen}{U[t]} - \textcolor{brown}{\theta}) \cdot \textcolor{ForestGreen}{U'[t]}$$


For our single neuron this is fine, but now we go into a new problem: the weight transport problem.


## The weight transport problem all over again



## Adding the reset term